{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d714970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from glob import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c364e3a",
   "metadata": {},
   "source": [
    "# 1. Load video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b845b4",
   "metadata": {},
   "source": [
    "https://m.blog.naver.com/dldudcks1779/222064172394\n",
    "resize : real-time camera capture 이미지 크기에 맞게 변환\n",
    "1) 변환할 이미지\n",
    "2) 변환할 이미지 크기(가로, 세로)\n",
    "- interpolation : 보간법 지정\n",
    "  - 보간법 : 알려진 데이터 지점 내에서 새로운 데이터 지점을 구성하는 방식\n",
    "  - cv2.INTER_NEAREST : 최근방 이웃 보간법\n",
    "  - cv2.INTER_LINEAR(default) : 양선형 보간법(2x2 이웃 픽셀 참조)\n",
    "  - cv2.INTER_CUBIC : 3차 회선 보간법(4x4 이웃 픽셀 참조)\n",
    "  - cv2.INTER_LANCZOS4 : Lanczos 보간법(8x8 이웃 픽셀 참조)\n",
    "  - cv2.INTER_AREA : 픽셀 영역 관계를 이용한 resampling 방법으로 이미지 축소시 효과적\n",
    "- resize_frame = cv2.resize(frame, (640, 480), interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a2e527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./원시데이터\\\\NIA_SL_SEN0001_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0001_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0001_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0001_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0001_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0002_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0002_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0002_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0002_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0002_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0003_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0003_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0003_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0003_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0003_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0004_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0004_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0004_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0004_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0004_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0005_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0005_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0005_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0005_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0005_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0006_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0006_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0006_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0006_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0006_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0007_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0007_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0007_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0007_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0007_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0008_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0008_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0008_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0008_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0008_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0009_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0009_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0009_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0009_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0009_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0010_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0010_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0010_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0010_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0010_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0011_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0011_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0011_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0011_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0011_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0012_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0012_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0012_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0012_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0012_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0013_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0013_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0013_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0013_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0013_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0014_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0014_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0014_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0014_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0014_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0015_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0015_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0015_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0015_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0015_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0016_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0016_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0016_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0016_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0016_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0017_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0017_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0017_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0017_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0017_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0018_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0018_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0018_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0018_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0018_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0019_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0019_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0019_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0019_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0019_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0020_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0020_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0020_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0020_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0020_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0021_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0021_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0021_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0021_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0021_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0022_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0022_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0022_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0022_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0022_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0023_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0023_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0023_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0023_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0023_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0024_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0024_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0024_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0024_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0024_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0025_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0025_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0025_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0025_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0025_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0026_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0026_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0026_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0026_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0026_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0027_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0027_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0027_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0027_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0027_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0028_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0028_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0028_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0028_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0028_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0029_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0029_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0029_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0029_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0029_REAL01_U.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0030_REAL01_D.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0030_REAL01_F.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0030_REAL01_L.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0030_REAL01_R.mp4',\n",
       " './원시데이터\\\\NIA_SL_SEN0030_REAL01_U.mp4']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './원시데이터/'\n",
    "file_list = glob(path+'*')\n",
    "\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779de2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 1920 1080 30.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# video 정보\n",
    "vid = cv2.VideoCapture(file_list[1])\n",
    "\n",
    "if not vid.isOpened(): \n",
    "    print(\"could not open :\",fn)\n",
    "    \n",
    "length = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width  = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = vid.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(length, width, height, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "126d7783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost : 5.85\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "vid = cv2.VideoCapture(file_list[1])\n",
    "\n",
    "if vid.isOpened() == False:\n",
    "    print('video read error')\n",
    "        \n",
    "while vid.isOpened():\n",
    "    \n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    resize_frame = cv2.resize(frame, (640, 480), interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow('frame', resize_frame)\n",
    "\n",
    "    if cv2.waitKey(25) % 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "            \n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('time cost : %.2f' %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5b1265b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "# frame size 비교\n",
    "print(frame.shape)\n",
    "print(resize_frame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a9b9d5",
   "metadata": {},
   "source": [
    "# 2. Holistic 적용 및 Keypoint 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45c52d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ca7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction. Model : holistic, image를 입력해 스켈레톤을 좌표값을 생성.\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "# 입력 image에 landmarks 얹는 함수.\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections\n",
    "    \n",
    "def draw_styled_landmarks(image, results):\n",
    "    # image : frame, results : model.predict(image)\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d62e1",
   "metadata": {},
   "source": [
    "- 특이사항 : mediapipe 적용시 원본 동영상에 비해 동영상이 느려짐. (resize관계 무)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ba6f6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "time cost : 16.29\n"
     ]
    }
   ],
   "source": [
    "path = './원시데이터/'\n",
    "file_list = glob(path+'*')\n",
    "\n",
    "start = time.time()\n",
    "vid = cv2.VideoCapture(file_list[1])\n",
    "\n",
    "if vid.isOpened() == False:\n",
    "    print('video read error')\n",
    "       \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while vid.isOpened():\n",
    "\n",
    "        ret, frame = vid.read()\n",
    "        \n",
    "        # check input ret\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (640, 480), interpolation=cv2.INTER_CUBIC)\n",
    "        image, results = mediapipe_detection(frame, holistic) # 예측 : 스켈레톤 생성.\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results) # 이미지에 스켈레톤 얹기.\n",
    "\n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)        \n",
    "        \n",
    "        if cv2.waitKey(25) % 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "print('time cost : %.2f' %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df92fbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,) (1404,) (63,) (63,)\n"
     ]
    }
   ],
   "source": [
    "# pose, face, lh, rh 좌표값 리스트화.\n",
    "# 132 = 33 x 4\n",
    "pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "# 1404 = 468 x 3\n",
    "face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)\n",
    "# 63 = 21 x 3\n",
    "lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "\n",
    "print(pose.shape, face.shape, lh.shape, rh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1abc2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수화 : 각 좌표값을 한 ndarray로 concat.\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c99a8805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1662,),\n",
       " array([ 0.50001252,  0.22932841, -0.53278667, ...,  0.38931453,\n",
       "         0.96375936,  0.01161412]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test = extract_keypoints(results)\n",
    "\n",
    "# 1662 = 132 + 1404 + 63*2\n",
    "result_test.shape, result_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d5a5d",
   "metadata": {},
   "source": [
    "# 3. Collect Keypoint Values for Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c0569d",
   "metadata": {},
   "source": [
    "## 파일정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a835aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "\n",
    "def call_info(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "        name = json_data['data'][0]['attributes'][0]['name'] \n",
    "\n",
    "        # print(json.dumps(json_data, indent=4) )\n",
    "        # print(name)\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee433d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'왼쪽': 10,\n",
       "         '오른쪽': 10,\n",
       "         '여기': 10,\n",
       "         '저기': 10,\n",
       "         '운전': 15,\n",
       "         '가다': 5,\n",
       "         '시간': 10,\n",
       "         '급하다': 10,\n",
       "         '약속': 10,\n",
       "         '나': 10,\n",
       "         '당신': 10,\n",
       "         '그남자': 10,\n",
       "         '말하다': 5,\n",
       "         '말해주다': 5,\n",
       "         '위험': 10,\n",
       "         '항상': 10})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample files\n",
    "sample_video_path = './원시데이터'\n",
    "sample_morpheme_path = './라벨링데이터/morpheme/'\n",
    "\n",
    "sample_video_files = glob(sample_video_path + '/*')\n",
    "sample_morpheme_files = glob(sample_morpheme_path + '/*')\n",
    "\n",
    "# count sample file \n",
    "actions=[]\n",
    "for video_file, morpheme_file in zip(sample_video_files, sample_morpheme_files):\n",
    "    action = call_info(morpheme_file)\n",
    "    actions.append(action)\n",
    "    \n",
    "actions = collections.Counter(actions)\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d8b466db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dir\n",
    "path = './custom_keypoints'\n",
    "for video_file, morpheme_file in zip(sample_video_files, sample_morpheme_files):\n",
    "    action = call_info(morpheme_file)\n",
    "    file_name = video_file.split('\\\\')[-1][:-4]\n",
    "    save_path = os.path.join(path, action, file_name)\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d301bef",
   "metadata": {},
   "source": [
    "## Keypoint 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bf4f880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIA_SL_SEN0001_REAL01_D\ttime cost : 18.68\n",
      "NIA_SL_SEN0001_REAL01_F\ttime cost : 20.18\n",
      "NIA_SL_SEN0001_REAL01_L\ttime cost : 18.92\n",
      "NIA_SL_SEN0001_REAL01_R\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     29\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(frame, (\u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m480\u001b[39m), interpolation\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_CUBIC)\n\u001b[1;32m---> 30\u001b[0m image, results \u001b[38;5;241m=\u001b[39m \u001b[43mmediapipe_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholistic\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 예측 : 스켈레톤 생성.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Draw landmarks\u001b[39;00m\n\u001b[0;32m     33\u001b[0m draw_styled_landmarks(image, results) \u001b[38;5;66;03m# 이미지에 스켈레톤 얹기.\u001b[39;00m\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mmediapipe_detection\u001b[1;34m(image, model)\u001b[0m\n\u001b[0;32m      2\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB) \u001b[38;5;66;03m# COLOR CONVERSION BGR 2 RGB\u001b[39;00m\n\u001b[0;32m      3\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m                  \u001b[38;5;66;03m# Image is no longer writeable\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m                 \u001b[38;5;66;03m# Make prediction. Model : holistic, image를 입력해 스켈레톤을 좌표값을 생성.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m                   \u001b[38;5;66;03m# Image is now writeable \u001b[39;00m\n\u001b[0;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR) \u001b[38;5;66;03m# COLOR COVERSION RGB 2 BGR\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\k-digital\\lib\\site-packages\\mediapipe\\python\\solutions\\holistic.py:160\u001b[0m, in \u001b[0;36mHolistic.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    137\u001b[0m   \u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\k-digital\\lib\\site-packages\\mediapipe\\python\\solution_base.py:334\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    328\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    330\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    331\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    332\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 334\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m solution_outputs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolutionOutputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    # LOOP through actions\n",
    "    for video_file, morpheme_file in zip(sample_video_files, sample_morpheme_files):\n",
    "        start = time.time()\n",
    "\n",
    "        action = call_info(morpheme_file)\n",
    "        file_name = video_file.split('\\\\')[-1][:-4]\n",
    "\n",
    "        \n",
    "        # load video file\n",
    "        print(file_name, end='\\t')\n",
    "        vid = cv2.VideoCapture(video_file)\n",
    "\n",
    "        if vid.isOpened() == False:\n",
    "            print('video read error')\n",
    "        \n",
    "        sequence_length = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        for frame_num in range(sequence_length):\n",
    "            ret, frame = vid.read()\n",
    "\n",
    "            # check input ret\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "                \n",
    "            frame = cv2.resize(frame, (640, 480), interpolation=cv2.INTER_CUBIC)\n",
    "            image, results = mediapipe_detection(frame, holistic) # 예측 : 스켈레톤 생성.\n",
    "\n",
    "            # Draw landmarks\n",
    "            draw_styled_landmarks(image, results) # 이미지에 스켈레톤 얹기.\n",
    "\n",
    "            # Show to screen\n",
    "            cv2.imshow('OpenCV Feed', image)        \n",
    "            \n",
    "            # NEW Export keypoints\n",
    "            save_path = os.path.join('./custom_keypoints', action, file_name, str(frame_num))\n",
    "            keypoints = extract_keypoints(results) # result : 스켈레톤 좌표값.\n",
    "            np.save(save_path, keypoints)\n",
    "            \n",
    "            if cv2.waitKey(25) % 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        vid.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        print(f'time cost : {(time.time() - start):.2f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da10d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
