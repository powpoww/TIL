{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "671dcda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "seed=124\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "font = ImageFont.truetype('fonts/gulim.ttc', 30)\n",
    "colors = [(245,117,16), (117,245,16), (16,117,245), (255,227,79), (254,218,249), (0,102,51), (96,96,96)]\n",
    "\n",
    "def prob_viz(res, actions, sentence, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    \n",
    "    # show prob\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "    \n",
    "    # show text box\n",
    "    cv2.rectangle(output_frame, (0,0), (640, 40), (245, 117, 16), -1) # 텍스트박스\n",
    "    \n",
    "    # show sentence text\n",
    "    output_frame = Image.fromarray(output_frame)\n",
    "    draw = ImageDraw.Draw(output_frame)\n",
    "    draw.text( (3,3) , ' '.join(sentence), font=font, fill= (255,255,255))\n",
    "    \n",
    "    # show prob text\n",
    "    for num, prob in enumerate(res):\n",
    "        draw.text((0, 60+num*40), actions[num], font=font, fill= (255,255,255))\n",
    "\n",
    "        \n",
    "    return np.array(output_frame)\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction. Model : holistic, image를 입력해 스켈레톤을 좌표값을 생성.\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    # image : frame, results : model.predict(image)\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    \n",
    "    # 함수화 : 각 좌표값을 한 ndarray로 concat.\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])\n",
    "\n",
    "\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe9321d",
   "metadata": {},
   "source": [
    "# 0. Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f70a9cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape : (105, 20, 1662)\n",
      "y shape : (105, 7)\n",
      "Train shape : ((94, 20, 1662), (94, 7))\n",
      "Test shape : ((11, 20, 1662), (11, 7))\n"
     ]
    }
   ],
   "source": [
    "# Path\n",
    "DATA_PATH = os.path.join('./Data/keypoint/20fps_6') \n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 15\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 20\n",
    "\n",
    "actions = np.array(['나', '목', '아프다', '병원', '어디', '너', '사랑'])\n",
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "\n",
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "        \n",
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "\n",
    "print(f'X shape : {X.shape}')\n",
    "print(f'y shape : {y.shape}')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)\n",
    "print(f'Train shape : {X_train.shape, y_train.shape}')\n",
    "print(f'Test shape : {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3559ed09",
   "metadata": {},
   "source": [
    "# 1. Build and Train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b2b8bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "86806b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name= '20fps_act7_11'\n",
    "log_dir = os.path.join(f'./logs/{name}')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b7d7041d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(20,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "64f1f0b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 1.0718 - categorical_accuracy: 0.6170\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.8349 - categorical_accuracy: 0.5745\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.7665 - categorical_accuracy: 0.5957\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.7296 - categorical_accuracy: 0.6383\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6878 - categorical_accuracy: 0.7128\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.5143 - categorical_accuracy: 0.8191\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.5372 - categorical_accuracy: 0.8085\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.4002 - categorical_accuracy: 0.9043\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.3900 - categorical_accuracy: 0.9149\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.3115 - categorical_accuracy: 0.9255\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.2713 - categorical_accuracy: 0.9255\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.2446 - categorical_accuracy: 0.9255\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.2178 - categorical_accuracy: 0.9255\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.2030 - categorical_accuracy: 0.9362\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.1716 - categorical_accuracy: 0.9681\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1712 - categorical_accuracy: 0.9362\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.1849 - categorical_accuracy: 0.9574\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.1437 - categorical_accuracy: 0.9574\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.1517 - categorical_accuracy: 0.9468\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.1961 - categorical_accuracy: 0.9255\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.4331 - categorical_accuracy: 0.8298\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.4755 - categorical_accuracy: 0.8298\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6329 - categorical_accuracy: 0.8085\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.2298 - categorical_accuracy: 0.5319\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.9346 - categorical_accuracy: 0.5851\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.8666 - categorical_accuracy: 0.6702\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.8418 - categorical_accuracy: 0.7128\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7384 - categorical_accuracy: 0.7447\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.7006 - categorical_accuracy: 0.7021\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.5632 - categorical_accuracy: 0.7660\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.4793 - categorical_accuracy: 0.7872\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.4726 - categorical_accuracy: 0.8191\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.4613 - categorical_accuracy: 0.7872\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5786 - categorical_accuracy: 0.7128\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.4450 - categorical_accuracy: 0.7979\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.3735 - categorical_accuracy: 0.8723\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.3597 - categorical_accuracy: 0.8511\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.3142 - categorical_accuracy: 0.8936\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.3166 - categorical_accuracy: 0.8723\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.2763 - categorical_accuracy: 0.8830\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.2815 - categorical_accuracy: 0.8723\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.2472 - categorical_accuracy: 0.8830\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.4769 - categorical_accuracy: 0.7872\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.4340 - categorical_accuracy: 0.8085\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3493 - categorical_accuracy: 0.8936\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3480 - categorical_accuracy: 0.8085\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.3476 - categorical_accuracy: 0.8298\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.3651 - categorical_accuracy: 0.8404\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.4600 - categorical_accuracy: 0.8191\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.4823 - categorical_accuracy: 0.7766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17dace269a0>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fedd865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'weights'\n",
    "model_name = f'{name}.h5'\n",
    "model.save(os.path.join(model_path, model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b0c7f6",
   "metadata": {},
   "source": [
    "# 2. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf070d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0]\n",
      " [0 0 0 2 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 1 0]\n",
      " [1 0 0 0 0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       0.50      1.00      0.67         1\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       1.00      0.50      0.67         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.74      0.79      0.73        11\n",
      "weighted avg       0.80      0.82      0.78        11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GW\\anaconda3\\envs\\k-digital\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\GW\\anaconda3\\envs\\k-digital\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\GW\\anaconda3\\envs\\k-digital\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "\n",
    "print(confusion_matrix(ytrue, yhat))\n",
    "print(classification_report(ytrue, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d77760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
